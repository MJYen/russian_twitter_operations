{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import API \n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Cursor\n",
    "import tweepy\n",
    "\n",
    "import pandas as pd\n",
    "import time,json\n",
    "from twitter_client import get_twitter_client\n",
    "\n",
    "import spacy\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import os.path\n",
    "import sys \n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescue_code(function):\n",
    "    import inspect\n",
    "    get_ipython().set_next_input(\"\".join(inspect.getsourcelines(function)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescue_code(get_top_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler('key', 'key')\n",
    "auth.set_access_token('key', 'key')\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "def get_tweets (user_list, dir_name):\n",
    "    '''\n",
    "    The funciton takes in a list of users to collect their tweets and directory name\n",
    "    where the tweet jsonl's will be saved\n",
    "    '''\n",
    "    \n",
    "    path = f'{dir_name}'\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "            print (\"Successfully created the directory %s \" % path)\n",
    "    client = api\n",
    "    for user in user_list:\n",
    "        fname = f'{dir_name}/user_timeline_{user}.jsonl'\n",
    "        with open(fname, 'w') as f:\n",
    "            for page in Cursor(client.user_timeline, tweet_mode='extended', screen_name=user, count=200).pages(16):\n",
    "                for status in page:\n",
    "                    f.write(json.dumps(status._json)+\"\\n\")\n",
    "                    \n",
    "def get_urls(tweets_df):\n",
    "    '''\n",
    "    The function takes in a tweets dataframe and returns urls that the user tweeted \n",
    "    '''\n",
    "    \n",
    "    tweets_urls = pd.DataFrame(tweets_df['entities'].values.tolist(), index=tweets_df.index)\n",
    "    tweets_urls = pd.DataFrame(tweets_data['urls'].values.tolist(), index=tweets_urls.index)\n",
    "    tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist())\n",
    "    tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist())\n",
    "    urls = tweets_urls[0].dropna().apply(pd.Series)\n",
    "    return urls\n",
    "                    \n",
    "def get_tweet_id_list(filepath):\n",
    "    '''\n",
    "    The function takes in a tweets jsonl filepath and return a list of tweet id's. The list can be\n",
    "    later used to collect retweeters, up to 100 per tweet\n",
    "    '''\n",
    "    tweets = pd.read_json (filepath, lines = True)\n",
    "    tweet_ids = tweets['id'].to_list()\n",
    "    return tweet_ids\n",
    "\n",
    "def get_top_interactions(file_path): \n",
    "    '''\n",
    "    The function takes in a filepath and returns a list of retweeters and returns a dataframe with\n",
    "    a count of interactions\n",
    "    '''\n",
    "    with open(file_path) as f:\n",
    "        lines = f.read()\n",
    "    df = pd.DataFrame(lines.strip('[').strip(']').split(\",\"))\n",
    "    df = pd.DataFrame(df[0].value_counts()).reset_index()\n",
    "    df.rename(columns = {'index':'user_id', 0:'weight'}, inplace = True)\n",
    "    df = df[df.weight > 10]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_retweeters(list_of_tweet_ids):\n",
    "    ''' \n",
    "    The function takes in a list of tweet ids and returns users who retweeted the tweet\n",
    "    '''\n",
    "    \n",
    "    retweeters = []\n",
    "    for x in list_of_tweet_ids:\n",
    "        for status in api.retweets(x):\n",
    "            retweeters.append(status.user.id)\n",
    "    return retweeters\n",
    "\n",
    "def get_screen_names(user_id_list):\n",
    "    '''\n",
    "    The function converts user id's to user_names by using Twitter API\n",
    "    '''\n",
    "    screen_names = []\n",
    "    for user_id in user_id_list:\n",
    "        try:\n",
    "            screen_name = api.get_user(user_id).screen_name\n",
    "            screen_names.append(screen_name)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return screen_names\n",
    "\n",
    "def get_tweets_for_retweeters(network_scv_filepath, tweets_storage_directory_name):\n",
    "    '''\n",
    "    The funciton takes in the network csv and an output directiory path.\n",
    "    The names are used to collect tweets and the directory name indicates\n",
    "    a path to stroe the collected tweets\n",
    "    '''\n",
    "    df = pd.read_csv(network_scv_filepath)\n",
    "    user_list = df['user_name'].tolist()\n",
    "    get_tweets(user_list, tweets_storage_directory_name)\n",
    "    \n",
    "\n",
    "def get_network_from_txt (input_file_fullpath, output_file_path_fullpath):\n",
    "    '''\n",
    "    The function takes in a filepath to a text file containing twitter ids for retweeters\n",
    "    and outputs a csv with users who have interacted with the account more than 10 times,\n",
    "    the function also coverts the users ids to screen names\n",
    "    '''\n",
    "    df = get_top_interactions(input_file_fullpath)\n",
    "    account_l_length = len(df['user_id'])\n",
    "    print(f'{account_l_length} total accounts to process')\n",
    "    df['user_name']=get_screen_names(df['user_id'])\n",
    "    network = df.astype(str)\n",
    "    network.to_csv(f'{output_file_path_fullpath}.csv')\n",
    "\n",
    "def get_post_freq(depository_path): #gets a number of posts a day per user form a json in a directory\n",
    "    import glob, os\n",
    "    os.chdir(depository_path)\n",
    "    name_avg_posts= []\n",
    "    for file in glob.glob(\"*.jsonl\"):\n",
    "        df = pd.read_json (file, lines = True)\n",
    "        df['dates'] = df['created_at'].dt.date\n",
    "        dates = pd.DataFrame(df['dates'].value_counts()).reset_index()\n",
    "        name=depository_path[31:-6]\n",
    "        retweet_percentage = len(df[df['full_text'].str.contains('RT')])/len(df['full_text'])\n",
    "        name_avg_posts.append([name,dates['dates'].mean(),retweet_percentage])\n",
    "    freq_matrix_df = pd.DataFrame(name_avg_posts, columns = ['name', 'post_freq', 'retweet_perc'])\n",
    "    freq_matrix_df.to_csv(f'{depository_path}freq_matrix.csv')\n",
    "    return freq_matrix_df\n",
    "\n",
    "def get_mentions_from_json(json_file):\n",
    "    ''' \n",
    "    The function takes the tweets json file and extracts all the entities that were\n",
    "    mentioned by the author\n",
    "    '''\n",
    "    try:\n",
    "        mentions = pd.read_json (json_file, lines = True) #read the json into a pd dataframe\n",
    "        mentions = pd.DataFrame( mentions['entities'].values.tolist(), index=mentions.index) #break down the entities column\n",
    "        mentions = pd.DataFrame( mentions['user_mentions'].values.tolist(), index=mentions.index) #bread down the user mentions\n",
    "        mentions = mentions.stack().reset_index() #put all the mentions in one column\n",
    "        mentions = pd.DataFrame( mentions[0].values.tolist(), index=mentions.index)\n",
    "        mentions_count = pd.DataFrame(mentions['screen_name'].value_counts().reset_index()) #count all the screename values\n",
    "        mentions_count.rename(columns = {'index':'user_names','screen_name':'count'}, inplace = True) #rename columns\n",
    "        name = json_file.rsplit('\\\\', 1)[1] #convert the json name to a name by dropping the path\n",
    "        name=name[14:-6] #convert the jason name to a variable name by dropping .jsonl\n",
    "        mentions_count['user']=name #creating a user column to indicate the outgoing node\n",
    "        return mentions_count\n",
    "    except:\n",
    "        print (f\"couldn't get entities from {json_file}\")\n",
    "        pass\n",
    "\n",
    "def get_all_nodes_edges(path):\n",
    "    import json\n",
    "    import os\n",
    "    import glob\n",
    "    import pprint\n",
    "    edges_for_nodes = []\n",
    "    for filename in glob.glob(os.path.join(path, '*.jsonl')): #only process .JSON files in folder.\n",
    "        edges_for_nodes.append(get_mentions_from_json(f'{filename}'))\n",
    "    df = pd.concat(edges_for_nodes)\n",
    "    df.rename(columns = {'count':'weight', 'user_names':'target', 'user':'source'}, inplace = True)\n",
    "    df.to_csv(f'{path}full_edge_list.csv',  index=False)\n",
    "\n",
    "def get_friends(screeen_name_list):\n",
    "    friends_collection = pd.DataFrame()\n",
    "    for x in screeen_name_list:\n",
    "        ids = []\n",
    "        for page in tweepy.Cursor(api.followers_ids, screen_name=x).pages():\n",
    "            ids.extend(page)\n",
    "\n",
    "        screen_names = [user.screen_name for user in api.lookup_users(user_ids=ids)]\n",
    "        screen_names_df = pd.DataFrame(screen_names)\n",
    "        screen_names_df['name'] = x\n",
    "        friends_collection = pd.concat(friends_collection,screen_names_df)\n",
    "    return friends_collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_articles = pd.read_json('data/user_timeline_RT_com.jsonl', lines = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(tweets_df):\n",
    "    '''\n",
    "    The function takes in a tweets dataframe and returns urls that the user tweeted \n",
    "    '''\n",
    "    \n",
    "    tweets_data = pd.DataFrame(tweets_df['entities'].values.tolist(), index=tweets_df.index)\n",
    "    tweets_urls = pd.DataFrame(tweets_data['urls'].values.tolist(), index=tweets_urls.index)\n",
    "    tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist())\n",
    "    urls = tweets_urls[0].dropna().apply(pd.Series)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "RT_articles = pd.read_json('data/user_timeline_RT_com.jsonl', lines = True )\n",
    "RT_articles = RT_articles[RT_articles['retweet_count']>80]\n",
    "print(len(RT_articles['id']))\n",
    "tweets_urls = pd.DataFrame(RT_articles['entities'].values.tolist(), index=RT_articles.index)\n",
    "tweets_urls = pd.DataFrame(tweets_urls['urls'].values.tolist(), index=tweets_urls.index)\n",
    "tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist(), index=tweets_urls.index)\n",
    "tweets_urls\n",
    "#tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist())\n",
    "#urls = tweets_urls[0].dropna().apply(pd.Series)\n",
    "tweets_urls.to_csv('RT_urls_with_over_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_over_80(jsonfile_path):   \n",
    "    RT_articles = pd.read_json('jsonfile_path', lines = True )\n",
    "    RT_articles = RT_articles[RT_articles['retweet_count']>20]\n",
    "    print(len(RT_articles['id']))\n",
    "    tweets_urls = pd.DataFrame(RT_articles['entities'].values.tolist(), index=RT_articles.index)\n",
    "    tweets_urls = pd.DataFrame(tweets_urls['urls'].values.tolist(), index=tweets_urls.index)\n",
    "    tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist(), index=tweets_urls.index)\n",
    "    tweets_urls\n",
    "    #tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist())\n",
    "    #urls = tweets_urls[0].dropna().apply(pd.Series)\n",
    "    tweets_urls.to_csv('sputnik_urls_with_over_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "         0\n",
      "7     None\n",
      "14    None\n",
      "18    None\n",
      "19    None\n",
      "72    None\n",
      "...    ...\n",
      "3121  None\n",
      "3126  None\n",
      "3136  None\n",
      "3170  None\n",
      "3174  None\n",
      "\n",
      "[357 rows x 1 columns]\n",
      "21\n",
      "                          url             expanded_url      display_url  \\\n",
      "196   https://t.co/KyJ7g0MFSO  https://sptnkne.ws/Cpfx  sptnkne.ws/Cpfx   \n",
      "201   https://t.co/GwHNa68NdW  https://sptnkne.ws/CpeJ  sptnkne.ws/CpeJ   \n",
      "403   https://t.co/95P0rwHJEB  https://sptnkne.ws/CnDm  sptnkne.ws/CnDm   \n",
      "415   https://t.co/exbLARklZ1  https://sptnkne.ws/CnBt  sptnkne.ws/CnBt   \n",
      "433   https://t.co/dyPOpJ9abE  https://sptnkne.ws/Cn8H  sptnkne.ws/Cn8H   \n",
      "651   https://t.co/HzSzZKllMO  https://sptnkne.ws/CmUY  sptnkne.ws/CmUY   \n",
      "883   https://t.co/TePZRDhjsF  https://sptnkne.ws/Cmsn  sptnkne.ws/Cmsn   \n",
      "1091  https://t.co/W1sYEglSd8  https://sptnkne.ws/CkFr  sptnkne.ws/CkFr   \n",
      "1333  https://t.co/qX2t2dDWku   http://sptnkne.ws/CjXt  sptnkne.ws/CjXt   \n",
      "1376  https://t.co/BK6VM1ixb2  https://sptnkne.ws/CjXt  sptnkne.ws/CjXt   \n",
      "1469  https://t.co/M6MnASWa1C  https://sptnkne.ws/CjBh  sptnkne.ws/CjBh   \n",
      "1645  https://t.co/qAM0ueXoB4  https://sptnkne.ws/CjhM  sptnkne.ws/CjhM   \n",
      "1879  https://t.co/fRGa1tL803  https://sptnkne.ws/Ch7D  sptnkne.ws/Ch7D   \n",
      "2098  https://t.co/5S2VF1QnAm  https://sptnkne.ws/CgU2  sptnkne.ws/CgU2   \n",
      "2219  https://t.co/HoMF6eH18N  https://sptnkne.ws/Cg8e  sptnkne.ws/Cg8e   \n",
      "2310  https://t.co/20rubZugOo  https://sptnkne.ws/Cgpk  sptnkne.ws/Cgpk   \n",
      "2481  https://t.co/qpBJBPqQM8   http://sptnkne.ws/CfAv  sptnkne.ws/CfAv   \n",
      "2556  https://t.co/mlM49UD4wF  https://sptnkne.ws/Cf9k  sptnkne.ws/Cf9k   \n",
      "2924  https://t.co/xZoK3jnAv6  https://sptnkne.ws/Ce3X  sptnkne.ws/Ce3X   \n",
      "3107  https://t.co/yw7buLvtga  https://sptnkne.ws/CdZz  sptnkne.ws/CdZz   \n",
      "3170  https://t.co/CVb34ZxPeL  https://sptnkne.ws/CdUr  sptnkne.ws/CdUr   \n",
      "\n",
      "         indices  \n",
      "196    [84, 107]  \n",
      "201     [59, 82]  \n",
      "403   [123, 146]  \n",
      "415   [106, 129]  \n",
      "433     [73, 96]  \n",
      "651    [91, 114]  \n",
      "883     [58, 81]  \n",
      "1091    [61, 84]  \n",
      "1333    [71, 94]  \n",
      "1376    [71, 94]  \n",
      "1469    [63, 86]  \n",
      "1645    [63, 86]  \n",
      "1879    [45, 68]  \n",
      "2098    [59, 82]  \n",
      "2219   [92, 115]  \n",
      "2310    [62, 85]  \n",
      "2481  [105, 128]  \n",
      "2556   [88, 111]  \n",
      "2924    [65, 88]  \n",
      "3107    [69, 92]  \n",
      "3170  [114, 137]  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-bccf634e0f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_urls_over_80\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'data/user_timeline_Ruptly.jsonl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_urls_over_80\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'data/user_timeline_SputnikInt.jsonl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-142-a3ef3c89c51b>\u001b[0m in \u001b[0;36mget_urls_over_80\u001b[1;34m(jsonfile_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#tweets_urls = pd.DataFrame(tweets_urls[0].values.tolist())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0murls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RT_urls_with_over_80_retweets'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "get_urls_over_80 ('data/user_timeline_Ruptly.jsonl')\n",
    "get_urls_over_80 ('data/user_timeline_SputnikInt.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't get entities from output/rt_Sputnik\\user_timeline_Marlyn99802970.jsonl\n"
     ]
    }
   ],
   "source": [
    "get_all_nodes_edges('output/rt_Sputnik/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory C:\\Users\\Viktor Avdulov\\Milestone\\output\\rt_Sputnik\\ failed\n",
      "Empty DataFrame\n",
      "Columns: [user_id, weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "get_tweets_for_retweeters('C:\\\\Users\\\\Viktor Avdulov\\\\Milestone\\\\output\\\\sputnik_retweeters.txt', 'C:\\\\Users\\\\Viktor Avdulov\\\\Milestone\\\\output\\\\rt_Sputnik\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Viktor Avdulov\\\\Milestone\\\\output\\\\sputnik_retweeters.txt', header = None).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friends(screeen_name_list):\n",
    "    friends_collection = pd.DataFrame()\n",
    "    for x in screeen_name_list:\n",
    "        ids = []\n",
    "        for page in tweepy.Cursor(api.followers_ids, screen_name=x).pages():\n",
    "            ids.extend(page)\n",
    "\n",
    "        screen_names = [user.screen_name for user in api.lookup_users(user_ids=ids)]\n",
    "        screen_names_df = pd.DataFrame(screen_names)\n",
    "        screen_names_df['name'] = x\n",
    "        friends_collection = pd.concat(friends_collection,screen_names_df)\n",
    "    return friends_collection\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 896\n",
      "Rate limit reached. Sleeping for: 895\n",
      "Rate limit reached. Sleeping for: 895\n",
      "Rate limit reached. Sleeping for: 896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-b7b9fe553825>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfriends_of_RT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_friends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfriends_of\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-c8a66b4c01ea>\u001b[0m in \u001b[0;36mget_friends\u001b[1;34m(screeen_name_list)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscreeen_name_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfollowers_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m         data, cursors = self.method(cursor=self.next_cursor,\n\u001b[0;32m     72\u001b[0m                                     \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                                     **self.kargs)\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_cursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_cursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m                                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                                         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rate limit reached. Sleeping for: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep_time\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# sleep for few extra sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;31m# if self.wait_on_rate_limit and self._reset_time is not None and \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "friends_of_RT = get_friends(friends_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv('output/rt_RT/full_RT_edge_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "degree_2 = pd.DataFrame(users_df['target'].value_counts().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_2 = degree_2[degree_2['target']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3749"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_of = degree_2['index'].tolist()\n",
    "len(friends_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a list of entities to discover and screen settings to fully display the dataframe fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this step we defined the list of entities that were of interest to us. Specifically the media outlets contorlled by Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_entities = ['SputnikInt', 'Ruptly', 'RT_com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change view of a dataframe to display full columns and full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 350) #show all columns\n",
    "#pd.set_option('display.max_colwidth', -1) #show all the text in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect tweets for the Russian media channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets(rus_entities, 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all tweet ids for the Russian media channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruptly_tweet_ids = get_tweet_id_list('data/user_timeline_Ruptly.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_tweet_ids = get_tweet_id_list('data/user_timeline_SputnikInt.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_tweet_ids = get_tweet_id_list('data/user_timeline_RT_com.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get twitter id's of the retweeters and save it to a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_retweeters = get_retweeters(sputnik_tweet_ids)\n",
    "with open('output/sputnik_retweeters_all.txt', 'w') as filehandle:\n",
    "    filehandle.write(str(sputnik_retweeters))\n",
    "    \n",
    "RT_retweeters = get_retweeters(RT_tweet_ids)\n",
    "with open('output/RT_retweeters_all.txt', 'w') as filehandle:\n",
    "    filehandle.write(str(RT_retweeters))\n",
    "    \n",
    "ruptly_retweeters = get_retweeters(ruptly_tweet_ids)\n",
    "with open('output/ruptly_retweeters_all.txt', 'w') as filehandle:\n",
    "    filehandle.write(str(ruptly_retweeters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top retweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_interactions = get_top_interactions ('output/rt_Sputnik/sputnik_retweeters_all.txt')\n",
    "RT_interactions = get_top_interactions ('output/RT_retweeters_all.txt')\n",
    "ruptly_interactions = get_top_interactions ('output/ruptly_retweeters_all.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert twitter ids to names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_names  = get_screen_names(sputnik_interactions)\n",
    "RT_names = get_screen_names(RT_interactions)\n",
    "ruptly_names = get_screen_names(ruptly_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweets for all retweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets(sputnik_retweeters_set, 'output/sputink_retweeters')\n",
    "get_tweets(RT_retweeters_set, 'output/RT_retweeters')\n",
    "get_tweets(ruptly_retweeters_set, 'output/ruptly_retweeters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all mentions from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_post_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explorador_IT = pd.read_json ('output/rt_ruptly/user_timeline_Explorador_IT.jsonl', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_top_interactions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0b611dc2f24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msputnik_interactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_interactions\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'output/rt_Sputnik/sputnik_retweeters_all.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_top_interactions' is not defined"
     ]
    }
   ],
   "source": [
    "sputnik_interactions = get_top_interactions ('output/rt_Sputnik/sputnik_retweeters_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "edges_for_nodes = []\n",
    "path = 'output/rt_ruptly/'\n",
    "for filename in glob.glob(os.path.join(path, '*.jsonl')): #only process .JSON files in folder.\n",
    "    edges_for_nodes.append(get_mentions_from_json(filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_for_nodes_df = edges_for_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges_for_nodes_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c57cf79c50f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0medges_for_nodes_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'edges_for_nodes_df' is not defined"
     ]
    }
   ],
   "source": [
    "edges_for_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explorador_IT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='output/rt_ruptly/user_timeline_Explorador_IT.jsonl'\n",
    "name=name[31:-6]\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweeters_sputnik = []\n",
    "for x in sputnik_tweet_id_list:\n",
    "    for status in api.retweets(x):\n",
    "        retweeters_sputnik.append(status.user.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sputnik_df = pd.DataFrame(retweeters_sputnik)\n",
    "rt_sput_df = pd.DataFrame(rt_sputnik_df[0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sput_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sput_df.rename(columns={0:'count', 'index':'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sput_df.to_csv('spuntic_count.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
